{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MS_Sweep.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBNyYzFFKFLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install 'wandb'\n",
        "import os \n",
        "os._exit(00)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXPQ9Y0wKJPR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkMBtojqKJbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "!pip install wandb\n",
        "import wandb\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzZ7yDBoKLEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os \n",
        "if not os.path.isdir('./FirstPersonActionRecognition'):\n",
        "    !git clone https://github.com/mldl2020/FirstPersonActionRecognition.git\n",
        "    !cp ./FirstPersonActionRecognition/*.py ./\n",
        "\n",
        "if not os.path.isdir('./GTEA61'):\n",
        "    !git clone https://github.com/MauriVass/GTEA61\n",
        "\n",
        "if not os.path.isdir(\"models\"):\n",
        "    os.mkdir(\"models\")\n",
        "\n",
        "!python3 fix_mmaps.py\n",
        "\n",
        "!mkdir \"7f\" \"16f\" \"25f\"\n",
        "!curl \"https://transfer.sh/r7MaZ/best_model_rgb_state_dict.pth\" -o best_model_rgb_state_dict.pth\n",
        "# !mv best_model_rgb_state_dict.pth ./7f/\n",
        "# !curl \"https://transfer.sh/hZB8Z/best_model_rgb_state_dict.pth\" -o best_model_rgb_state_dict.pth\n",
        "# !mv best_model_rgb_state_dict.pth ./16f/\n",
        "# !curl \"https://transfer.sh/Kwl9k/best_model_rgb_state_dict.pth\" -o best_model_rgb_state_dict.pth\n",
        "# !mv best_model_rgb_state_dict.pth ./25f/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kM1Dqp4CTHh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp ./best_model_rgb_state_dict.pth ./models/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5lvqTf3KPXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wandb login "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IFL3gzH5bLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf entropies\n",
        "!unzip entropies.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOKHe64EKSat",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import Config\n",
        "from gtea_dataset import gtea61\n",
        "from spatial_transforms import *\n",
        "from objectAttentionModelConvLSTM import *\n",
        "\n",
        "sweep_config = {\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "      'name': 'valid_accuracy_rgb',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        \"ms_task\": {\n",
        "            'values': [\"classifier\", \"regressor\"]\n",
        "        },\n",
        "        'lr': {\n",
        "            'values': [1e-3, 1e-4, 1e-5]\n",
        "        },\n",
        "        'ms_lr': {\n",
        "            'values': [1e-3, 1e-4, 1e-5]\n",
        "        },\n",
        "        'decay_steps': {\n",
        "            'values': [[100, 200], [200, 300]]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "# sweep_id = wandb.sweep(sweep_config, entity=\"eddy\", project=\"mldl-fpar\")\n",
        "sweep_id = \"eddy/mldl-fpar/g3ne8y3p\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uihqwkEsKWgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ms_sweep():\n",
        "    config_stage2_ms = Config({\"stage\": 2,\n",
        "                               \"ms\": True,\n",
        "                               \"ms_task\": \"classifier\",  # ms_task is either classifier or regressor\n",
        "                               \"ms_features\": \"CAM\",  # RN: ResNet, CAM: attention\n",
        "                               \"binary_mask_threshold\": 0.01,\n",
        "                               \"num_classes\": 61,\n",
        "                               \"batch_size\": 32,\n",
        "                               \"lstm_mem_size\": 512,\n",
        "                               \"lr\": 1e-4,\n",
        "                               \"ms_lr\": 1e-4,\n",
        "                               \"optimizer\": \"adam\",\n",
        "                               \"epochs\": 500,\n",
        "                               \"decay_steps\": [25, 75],\n",
        "                               \"decay_factor\": 0.1,\n",
        "                               \"weight_decay\": 5e-5,\n",
        "                               \"val_frequency\": 3,\n",
        "                               \"models_dir\": \"models\",\n",
        "                               \"seq_len\": 7,\n",
        "                               \"training_user_split\": [1, 3, 4],\n",
        "                               \"val_user_split\": [2],\n",
        "                               \"early_stopping_epochs\": 120})\n",
        "\n",
        "    def prepare_training_ms(config):\n",
        "        train_params_rgb = []\n",
        "        train_params_ms = []\n",
        "\n",
        "        model = attentionModel(num_classes=config.num_classes, mem_size=config.lstm_mem_size, ms=True, ms_task=config.ms_task)\n",
        "        stage1_dict = os.path.join(config.models_dir, 'best_model_rgb_state_dict.pth')\n",
        "        model.load_state_dict(torch.load(stage1_dict), strict=False)\n",
        "        model.train(False)\n",
        "        for params in model.parameters():\n",
        "            params.requires_grad = False\n",
        "        #\n",
        "        for params in model.resNet.layer4[0].conv1.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        for params in model.resNet.layer4[0].conv2.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        for params in model.resNet.layer4[1].conv1.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        for params in model.resNet.layer4[1].conv2.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        for params in model.resNet.layer4[2].conv1.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "        #\n",
        "        for params in model.resNet.layer4[2].conv2.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "        #\n",
        "        for params in model.resNet.fc.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        model.resNet.layer4[0].conv1.train(True)\n",
        "        model.resNet.layer4[0].conv2.train(True)\n",
        "        model.resNet.layer4[1].conv1.train(True)\n",
        "        model.resNet.layer4[1].conv2.train(True)\n",
        "        model.resNet.layer4[2].conv1.train(True)\n",
        "        model.resNet.layer4[2].conv2.train(True)\n",
        "        model.resNet.fc.train(True)\n",
        "\n",
        "        model.ms_conv.train(True)\n",
        "        model.ms_classifier.train(True)\n",
        "\n",
        "        for params in model.ms_conv.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_ms += [params]\n",
        "\n",
        "        for params in model.ms_classifier.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_ms += [params]\n",
        "\n",
        "        for params in model.lstm_cell.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        for params in model.classifier.parameters():\n",
        "            params.requires_grad = True\n",
        "            train_params_rgb += [params]\n",
        "\n",
        "        return model, train_params_rgb, train_params_ms\n",
        "\n",
        "    def training_ms(model, config, train_loader, val_loader):\n",
        "        wandb.watch(model, log=\"all\")\n",
        "        train_iter = 0\n",
        "        best_accuracy = 0\n",
        "        for epoch in range(config.epochs):\n",
        "            epoch_loss_rgb = 0\n",
        "            epoch_loss_ms = 0\n",
        "            num_corrects_rgb = 0\n",
        "            num_corrects_ms = 0\n",
        "            trainSamples = 0\n",
        "            map_pixel_samples = 0\n",
        "            iterPerEpoch = 0\n",
        "            model.lstm_cell.train(True)\n",
        "            model.classifier.train(True)\n",
        "            model.resNet.layer4[0].conv1.train(True)\n",
        "            model.resNet.layer4[0].conv2.train(True)\n",
        "            model.resNet.layer4[1].conv1.train(True)\n",
        "            model.resNet.layer4[1].conv2.train(True)\n",
        "            model.resNet.layer4[2].conv1.train(True)\n",
        "            model.resNet.layer4[2].conv2.train(True)\n",
        "            model.resNet.fc.train(True)\n",
        "            model.ms_conv.train(True)\n",
        "            model.ms_classifier.train(True)\n",
        "            # display_ms = True\n",
        "            for inputs_rgb, map_labels, labels in train_loader:\n",
        "                num_samples = inputs_rgb.size(0)\n",
        "                trainSamples += num_samples\n",
        "                train_iter += 1\n",
        "                iterPerEpoch += 1\n",
        "                optimizer_fn.zero_grad()\n",
        "                inputs_rgb = inputs_rgb.permute(1, 0, 2, 3, 4).to(config.device)  # but why?\n",
        "                labels = labels.to(config.device)\n",
        "                # map_labels = map_labels.to(config.device)\n",
        "                map_labels = map_labels.to(config.device).permute(0, 2, 1, 3, 4).squeeze()  # BSxseq_lenx7x7\n",
        "                output_label, _, output_map = model(inputs_rgb)  # output_map is BSx2\n",
        "                # if display_ms:\n",
        "                #     display_map_prediction(map_labels[0].clone(), output_map[0].clone(), loss_fn_ms)\n",
        "                #     display_ms = False\n",
        "                # map_labels = map_labels.view(num_samples * config.seq_len * 49)\n",
        "                # output_map = output_map.view(config.seq_len * num_samples * 49, 2)\n",
        "                map_pixel_samples += num_samples * config.seq_len * 7 * 7\n",
        "                loss_rgb = loss_fn_rgb(output_label, labels)\n",
        "                loss_ms = loss_fn_ms(output_map.squeeze(), map_labels)\n",
        "                loss = loss_rgb + loss_ms\n",
        "                loss.backward()\n",
        "                optimizer_fn.step()\n",
        "\n",
        "                _, predicted_rgb = torch.max(output_label.data, 1)\n",
        "                epoch_loss_rgb += loss_rgb.item()\n",
        "                predicted_rgb = predicted_rgb.to(config.device)\n",
        "                num_corrects_rgb += torch.sum(predicted_rgb == labels).data.item()\n",
        "\n",
        "                if config.ms_task == \"classifier\":\n",
        "                    _, predicted_ms = torch.max(output_map.data, 1)\n",
        "                    predicted_ms = predicted_ms.to(config.device)\n",
        "                    num_corrects_ms += torch.sum(predicted_ms == map_labels).data.item()\n",
        "                epoch_loss_ms += loss_ms.item()\n",
        "\n",
        "            optim_scheduler.step()\n",
        "            avg_loss_rgb = epoch_loss_rgb / iterPerEpoch\n",
        "            train_accuracy_rgb = (num_corrects_rgb / trainSamples)\n",
        "            avg_loss_ms = epoch_loss_ms / iterPerEpoch\n",
        "            if config.ms_task == \"classifier\":\n",
        "                train_accuracy_ms = (num_corrects_ms / map_pixel_samples)\n",
        "\n",
        "            print('Train: Epoch = {}/{} | Loss = {} | Accuracy = {}'.format(epoch + 1, config.epochs, avg_loss_rgb, train_accuracy_rgb))\n",
        "\n",
        "            max_loss = 6\n",
        "            avg_loss_normalized_rgb = avg_loss_rgb if avg_loss_rgb < max_loss else max_loss\n",
        "            avg_loss_normalized_ms = avg_loss_ms if avg_loss_ms < max_loss else max_loss\n",
        "            if config.ms_task == \"classifier\":\n",
        "                wandb.log({\"train_loss_rgb\": avg_loss_normalized_rgb,\n",
        "                           \"train_loss_ms\": avg_loss_normalized_ms,\n",
        "                           \"train_accuracy_rgb\": train_accuracy_rgb,\n",
        "                           \"train_accuracy_ms\": train_accuracy_ms,\n",
        "                           \"eopch\": (epoch + 1)})\n",
        "            else:\n",
        "                wandb.log({\"train_loss_rgb\": avg_loss_normalized_rgb,\n",
        "                           \"train_loss_ms\": avg_loss_normalized_ms,\n",
        "                           \"train_accuracy_rgb\": train_accuracy_rgb,\n",
        "                           \"eopch\": (epoch + 1)})\n",
        "\n",
        "            if (epoch + 1) % config.val_frequency == 0:\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "                    val_loss_epoch_rgb = 0\n",
        "                    val_loss_epoch_ms = 0\n",
        "                    val_iter = 0\n",
        "                    val_samples = 0\n",
        "                    num_corrects_rgb = 0\n",
        "                    num_corrects_ms = 0\n",
        "                    map_pixel_samples = 0\n",
        "                    for inputs_rgb, map_labels, labels in val_loader:\n",
        "                        val_iter += 1\n",
        "                        num_samples = inputs_rgb.size(0)\n",
        "                        val_samples += num_samples\n",
        "                        inputs_rgb = inputs_rgb.permute(1, 0, 2, 3, 4).to(config.device)\n",
        "                        labels = labels.to(config.device)\n",
        "                        # map_labels = map_labels.to(config.device)\n",
        "                        map_labels = map_labels.to(config.device).view(num_samples, config.seq_len, 7, 7)\n",
        "                        output_label, _, output_map = model(inputs_rgb)\n",
        "                        # map_labels = map_labels.view(num_samples * config.seq_len * 49)\n",
        "                        # output_map = output_map.view(config.seq_len * num_samples * 49, 2)\n",
        "                        map_pixel_samples += num_samples * config.seq_len * 7 * 7\n",
        "                        val_loss_rgb = loss_fn_rgb(output_label, labels)\n",
        "                        val_loss_ms = loss_fn_ms(output_map.squeeze(), map_labels)\n",
        "                        val_loss_epoch_rgb += val_loss_rgb.item()\n",
        "                        val_loss_epoch_ms += val_loss_ms.item()\n",
        "                        _, predicted_rgb = torch.max(output_label.data, 1)\n",
        "                        num_corrects_rgb += torch.sum(predicted_rgb == labels).data.item()\n",
        "                        if config.ms_task == \"classifier\":\n",
        "                            _, predicted_ms = torch.max(output_map.data, 1)\n",
        "                            num_corrects_ms += torch.sum(predicted_ms == map_labels).data.item()\n",
        "                val_accuracy_rgb = (num_corrects_rgb / val_samples)\n",
        "                avg_val_loss_rgb = val_loss_epoch_rgb / val_iter\n",
        "                avg_val_loss_ms = val_loss_epoch_ms / val_iter\n",
        "                if config.ms_task == \"classifier\":\n",
        "                    val_accuracy_ms = (num_corrects_ms / map_pixel_samples)\n",
        "                print('*****  Val: Epoch = {} | Loss {} | Accuracy = {} *****'.format(epoch + 1, avg_val_loss_rgb, val_accuracy_rgb))\n",
        "\n",
        "                avg_val_loss_normalized_rgb = avg_val_loss_rgb if avg_val_loss_rgb < max_loss else max_loss\n",
        "                avg_val_loss_normalized_ms = avg_val_loss_ms if avg_val_loss_ms < max_loss else max_loss\n",
        "                if config.ms_task == \"classifier\":\n",
        "                    wandb.log({\"valid_loss_rgb\": avg_val_loss_normalized_rgb,\n",
        "                               \"valid_loss_ms\": avg_val_loss_normalized_ms,\n",
        "                               \"valid_accuracy_rgb\": val_accuracy_rgb,\n",
        "                               \"valid_accuracy_ms\": val_accuracy_ms,\n",
        "                               \"eopch\": (epoch + 1)})\n",
        "                else:\n",
        "                    wandb.log({\"valid_loss_rgb\": avg_val_loss_normalized_rgb,\n",
        "                               \"valid_loss_ms\": avg_val_loss_normalized_ms,\n",
        "                               \"valid_accuracy_rgb\": val_accuracy_rgb,\n",
        "                               \"eopch\": (epoch + 1)})\n",
        "\n",
        "                if val_accuracy_rgb > best_accuracy:\n",
        "                    best_epoch = (epoch + 1)\n",
        "                    save_path_model = (config.models_dir + '/best_model_ms_state_dict.pth')\n",
        "                    torch.save(model.state_dict(), save_path_model)\n",
        "                    best_accuracy = val_accuracy_rgb\n",
        "                else:\n",
        "                    if (epoch + 1) - best_epoch > 120:\n",
        "                      print('Early stopping - Best epoch = {} | Current epoch = {} *****'.format(best_epoch, epoch + 1))\n",
        "                      return\n",
        "            else:\n",
        "                if (epoch + 1) % 10 == 0:\n",
        "                    save_path_model = (config.models_dir + '/best_model_ms_state_dict' + str(epoch + 1) + '.pth')\n",
        "                    # torch.save(model.state_dict(), save_path_model)\n",
        "        wandb.run.summary[\"best_valid_accuracy\"] = best_accuracy\n",
        "        return True\n",
        "\n",
        "\n",
        "    # SETUP RUN\n",
        "    run = wandb.init(config=config_stage2_ms.as_dict(), resume=True)\n",
        "    config = wandb.config\n",
        "\n",
        "    wandb.run.name = f'MS, {config.ms_task}, {config.lr}, {config.ms_lr}, {config.decay_steps}'\n",
        "    wandb.run.save()\n",
        "    wandb.run.summary[\"state\"] = \"unfinished\"\n",
        "\n",
        "    # PREPARE DATASET\n",
        "    config = config_stage2_ms\n",
        "    normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    transform_rgb_list = [Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224), ToTensor(), normalize]\n",
        "    if config.ms_task == 'classifier':\n",
        "        transform_ms_list = transform_rgb_list[:3] + [Scale(7), ToTensor(), ToBinaryMap(config.binary_mask_threshold)]\n",
        "    else:\n",
        "        transform_ms_list = transform_rgb_list[:3] + [Scale(7), ToTensor()]\n",
        "    transform_rgb = Compose(transform_rgb_list)\n",
        "    transform_ms = Compose(transform_ms_list)\n",
        "\n",
        "    gtea_root = \"GTEA61\"\n",
        "    train_dataset = gtea61(\"ms\", gtea_root, split=\"train\", user_split=config.training_user_split, seq_len_rgb=config.seq_len, transform_rgb=transform_rgb, transform_ms=transform_ms, preload=False, frame_sampler = \"entropy_based\")\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "\n",
        "    val_transform = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n",
        "    if config.ms_task == 'classifier':\n",
        "        val_transform_ms = Compose([Scale(256), CenterCrop(224), Scale(7), ToTensor(), ToBinaryMap(config.binary_mask_threshold)])\n",
        "    else:\n",
        "        val_transform_ms = Compose([Scale(256), CenterCrop(224), Scale(7), ToTensor()])\n",
        "    val_dataset = gtea61(\"ms\", gtea_root, split=\"test\", user_split=config.val_user_split, seq_len_rgb=config.seq_len, transform_rgb=val_transform, transform_ms=val_transform_ms, preload=False, frame_sampler = \"entropy_based\")\n",
        "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    #TRAINING\n",
        "\n",
        "\n",
        "    model, train_params_rgb, train_params_ms = prepare_training_ms(config)\n",
        "    model.lstm_cell.train(True)\n",
        "    model.classifier.train(True)\n",
        "\n",
        "    model.to(config.device)\n",
        "\n",
        "    loss_fn_rgb = nn.CrossEntropyLoss()\n",
        "    if config.ms_task == \"classifier\":\n",
        "        loss_fn_ms = nn.CrossEntropyLoss()\n",
        "    else:\n",
        "        loss_fn_ms = nn.MSELoss()\n",
        "\n",
        "    optimizer_fn = torch.optim.Adam([{'params': train_params_rgb}, {'params': train_params_ms, 'lr': config.ms_lr}], lr=config.lr, weight_decay=config.weight_decay, eps=1e-4)\n",
        "    optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=config.decay_steps, gamma=config.decay_factor)\n",
        "\n",
        "\n",
        "    success = training_ms(model, config, train_loader, val_loader)\n",
        "\n",
        "    if success:\n",
        "        wandb.run.summary[\"state\"] = \"finished\"\n",
        "    else:\n",
        "        wandb.run.summary[\"state\"] = \"failed\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6my6OAiOyBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stopping_threshold = 120\n",
        "\n",
        "wandb.agent(sweep_id, ms_sweep)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}