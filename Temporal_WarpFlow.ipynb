{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Temporal-WarpFlow",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViVAkUndllg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install 'torch==1.4.0'\n",
        "!pip3 install 'torchvision==0.5.0'\n",
        "!pip3 install 'Pillow-SIMD'\n",
        "!pip3 install 'tqdm'\n",
        "!pip3 install 'wandb'\n",
        "import os \n",
        "os._exit(00)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OimtV0Cch-6V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader, random_split\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import resnet34\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import wandb\n",
        "from datetime import datetime\n",
        "from utils import Config, test\n",
        "from gtea_dataset import gtea61"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu8fi6SJiGre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !wandb login ***"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB6BSkex_ixv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_flow = Config({\"num_classes\": 61,\n",
        "                      \"batch_size\": 32,\n",
        "                      \"lstm_mem_size\": 512,\n",
        "                      \"lr\": 1e-2,\n",
        "                      \"optimizer\": \"sgd\",\n",
        "                      \"sgd_momentum\": 0.9,\n",
        "                      \"epochs\": 750,\n",
        "                      \"decay_steps\": [150, 300, 500],\n",
        "                      \"decay_factor\": 0.5,\n",
        "                      \"weight_decay\": 5e-4,\n",
        "                      \"val_frequency\": 3,\n",
        "                      \"models_dir\": \"models\",\n",
        "                      \"seq_len\": 5,\n",
        "                      \"training_user_split\": [1, 3, 4],\n",
        "                      \"val_user_split\": [2]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaJapH1MifSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isdir('./FirstPersonActionRecognition'):\n",
        "    !git clone https://github.com/mldl2020/FirstPersonActionRecognition.git\n",
        "    !cp ./FirstPersonActionRecognition/*.py ./\n",
        "\n",
        "if not os.path.isdir('./GTEA61'):\n",
        "    !git clone https://github.com/MauriVass/GTEA61\n",
        "\n",
        "if not os.path.isdir('./'+config_flow.models_dir):\n",
        "    os.mkdir('./'+config_flow.models_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iEPJz-L1_kzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TrainingFlow(model, config):\n",
        "    wandb.watch(model, log=\"all\")\n",
        "    train_iter = 0\n",
        "    best_accuracy = 0\n",
        "    train = []\n",
        "    val = []\n",
        "    for epoch in range(config.epochs):\n",
        "        epoch_loss = 0\n",
        "        numCorrTrain = 0\n",
        "        trainSamples = 0\n",
        "        iterPerEpoch = 0\n",
        "        model.train(True)\n",
        "        for inputs, labels in train_loader:\n",
        "            train_iter += 1\n",
        "            iterPerEpoch += 1\n",
        "            optimizer_fn.zero_grad()\n",
        "            trainSamples += inputs.size(0)\n",
        "            inputs = inputs.to(config.device)\n",
        "            labels = labels.to(config.device)\n",
        "            output_label, _ = model(inputs)\n",
        "            loss = loss_fn(output_label, labels)\n",
        "            loss.backward()\n",
        "            optimizer_fn.step()\n",
        "            _, predicted = torch.max(output_label.data, 1)\n",
        "            numCorrTrain += torch.sum(predicted == labels).data.item()\n",
        "            epoch_loss += loss.item()\n",
        "        optim_scheduler.step()\n",
        "        avg_loss = epoch_loss / iterPerEpoch\n",
        "        trainAccuracy = (numCorrTrain / trainSamples)\n",
        "        print('Train: Epoch = {}/{} | Loss = {} | Accuracy = {}'.format(epoch + 1, config.epochs, avg_loss, trainAccuracy))\n",
        "\n",
        "        max_loss = 6\n",
        "        avg_loss_normalized = avg_loss if avg_loss < max_loss else max_loss\n",
        "        train.append((trainAccuracy, avg_loss_normalized))\n",
        "        wandb.log({\"train_loss\": avg_loss_normalized,\n",
        "                   \"train_accuracy\": trainAccuracy,\n",
        "                   \"eopch\": (epoch + 1)})\n",
        "\n",
        "        if (epoch + 1) % config.val_frequency == 0:\n",
        "            model.eval()\n",
        "            val_loss_epoch = 0\n",
        "            val_iter = 0\n",
        "            val_samples = 0\n",
        "            numCorr = 0\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    val_iter += 1\n",
        "                    val_samples += inputs.size(0)\n",
        "                    inputs = inputs.to(config.device)\n",
        "                    labels = labels.to(config.device)\n",
        "                    output_label, _ = model(inputs)\n",
        "                    val_loss = loss_fn(output_label, labels)\n",
        "                    val_loss_epoch += val_loss.item()\n",
        "                    _, predicted = torch.max(output_label.data, 1)\n",
        "                    numCorr += torch.sum(predicted == labels).data.item()\n",
        "            val_accuracy = (numCorr / val_samples)\n",
        "            avg_val_loss = val_loss_epoch / val_iter\n",
        "            print('*****  Validation: Epoch = {} | Loss = {} | Accuracy = {}  *****'.format(epoch + 1, avg_val_loss, val_accuracy))\n",
        "            avg_val_loss_normalized = avg_val_loss if avg_val_loss < max_loss else max_loss\n",
        "            val.append((val_accuracy, avg_val_loss_normalized))\n",
        "            wandb.log({\"valid_loss\": avg_val_loss_normalized,\n",
        "                       \"valid_accuracy\": val_accuracy,\n",
        "                       \"eopch\": (epoch + 1)})\n",
        "            if val_accuracy > best_accuracy:\n",
        "                save_path_model = os.path.join(config.models_dir, \"best_model_flow_state_dict.pth\")\n",
        "                torch.save(model.state_dict(), save_path_model)\n",
        "                best_accuracy = val_accuracy\n",
        "        else:\n",
        "            if (epoch + 1) % 10 == 0:\n",
        "                save_path_model = os.path.join(config.models_dir, 'model_flow_state_dict_epoch' + str(epoch + 1) + '.pth')\n",
        "                # torch.save(model.state_dict(), save_path_model)\n",
        "    wandb.run.summary[\"best_valid_accuracy\"] = best_accuracy\n",
        "    return train, val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZbnRQXH_r0f",
        "colab_type": "text"
      },
      "source": [
        "Perpare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nnkmjAA_m9E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gtea_dataset import gtea61\n",
        "from spatial_transforms import *\n",
        "from objectAttentionModelConvLSTM import *\n",
        "\n",
        "normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n",
        "                             ToTensor(), normalize])\n",
        "\n",
        "gtea_root = \"GTEA61\"\n",
        "config = config_flow\n",
        "train_dataset = gtea61(\"flow\", gtea_root, split=\"train\", user_split=config.training_user_split, seq_len_flow=config.seq_len, transform_flow=spatial_transform, preload=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, sampler=None, num_workers=4, pin_memory=True)\n",
        "\n",
        "val_transform = Compose([Scale(256), CenterCrop(224), ToTensor(), normalize])\n",
        "val_dataset = gtea61(\"flow\", gtea_root, split=\"test\", user_split=config.val_user_split, seq_len_flow=config.seq_len, transform_flow=val_transform, preload=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfNuZmb5_vAA",
        "colab_type": "text"
      },
      "source": [
        "Run Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkeABonf_n1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flow_resnet import flow_resnet34\n",
        "\n",
        "model = flow_resnet34(True, channels=2 * config.seq_len, num_classes=config.num_classes)\n",
        "model.train(True)\n",
        "train_params = list(model.parameters())\n",
        "model.to(config.device)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer_fn = torch.optim.SGD(train_params, lr=config.lr, momentum=config.sgd_momentum, weight_decay=config.weight_decay)\n",
        "optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=config.decay_steps, gamma=config.decay_factor)\n",
        "\n",
        "training_time = datetime.now().strftime(\"%d-%b_%H-%M\")\n",
        "wandb.init(config=config, group=f\"{config.seq_len}f\", name=f\"{training_time} Flow, {config.seq_len}f, T{str(config.training_user_split).replace(' ', '')}\", project=\"mldl-fpar\")\n",
        "\n",
        "train_flow, val_flow = TrainingFlow(model, config)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}